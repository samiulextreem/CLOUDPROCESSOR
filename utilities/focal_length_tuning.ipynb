{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4418ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 19 calibration images...\n",
      "Fixed fy: 900\n",
      "Varying fx: [850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300]\n",
      "Saved: calibration_fx850_fy900_1280x720.png\n",
      "Saved: calibration_fx850_fy900_1280x720.png\n",
      "Saved: calibration_fx875_fy900_1280x720.png\n",
      "Saved: calibration_fx875_fy900_1280x720.png\n",
      "Saved: calibration_fx900_fy900_1280x720.png\n",
      "Saved: calibration_fx900_fy900_1280x720.png\n",
      "Saved: calibration_fx925_fy900_1280x720.png\n",
      "Saved: calibration_fx925_fy900_1280x720.png\n",
      "Saved: calibration_fx950_fy900_1280x720.png\n",
      "Saved: calibration_fx950_fy900_1280x720.png\n",
      "Saved: calibration_fx975_fy900_1280x720.png\n",
      "Saved: calibration_fx975_fy900_1280x720.png\n",
      "Saved: calibration_fx1000_fy900_1280x720.png\n",
      "Saved: calibration_fx1000_fy900_1280x720.png\n",
      "Saved: calibration_fx1025_fy900_1280x720.png\n",
      "Saved: calibration_fx1025_fy900_1280x720.png\n",
      "Saved: calibration_fx1050_fy900_1280x720.png\n",
      "Saved: calibration_fx1050_fy900_1280x720.png\n",
      "Saved: calibration_fx1075_fy900_1280x720.png\n",
      "Saved: calibration_fx1075_fy900_1280x720.png\n",
      "Saved: calibration_fx1100_fy900_1280x720.png\n",
      "Saved: calibration_fx1100_fy900_1280x720.png\n",
      "Saved: calibration_fx1125_fy900_1280x720.png\n",
      "Saved: calibration_fx1125_fy900_1280x720.png\n",
      "Saved: calibration_fx1150_fy900_1280x720.png\n",
      "Saved: calibration_fx1150_fy900_1280x720.png\n",
      "Saved: calibration_fx1175_fy900_1280x720.png\n",
      "Saved: calibration_fx1175_fy900_1280x720.png\n",
      "Saved: calibration_fx1200_fy900_1280x720.png\n",
      "Saved: calibration_fx1200_fy900_1280x720.png\n",
      "Saved: calibration_fx1225_fy900_1280x720.png\n",
      "Saved: calibration_fx1225_fy900_1280x720.png\n",
      "Saved: calibration_fx1250_fy900_1280x720.png\n",
      "Saved: calibration_fx1250_fy900_1280x720.png\n",
      "Saved: calibration_fx1275_fy900_1280x720.png\n",
      "Saved: calibration_fx1275_fy900_1280x720.png\n",
      "Saved: calibration_fx1300_fy900_1280x720.png\n",
      "\n",
      "‚úÖ All 19 calibration images saved in 'fy900_fx_calibration_images/' folder\n",
      "üìÅ Browse the images to see how fx affects the horizontal perspective!\n",
      "Saved: calibration_fx1300_fy900_1280x720.png\n",
      "\n",
      "‚úÖ All 19 calibration images saved in 'fy900_fx_calibration_images/' folder\n",
      "üìÅ Browse the images to see how fx affects the horizontal perspective!\n"
     ]
    }
   ],
   "source": [
    "# Focal Length Calibration: fy=900, fx from 850 to 1300 with 25-step intervals\n",
    "import os\n",
    "\n",
    "def generate_fy_fx_calibration_images():\n",
    "    \"\"\"\n",
    "    Generate and save images with fixed fy=900 and fx from 850 to 1300 (step 25)\n",
    "    to test the effect of different fx values\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    output_dir = \"fy900_fx_calibration_images\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Fixed fy value and varying fx values\n",
    "    fy_fixed = 900\n",
    "    fx_values = range(850, 1325, 25)  # 850 to 1300 with 25-step intervals\n",
    "    \n",
    "    print(f\"Generating {len(fx_values)} calibration images...\")\n",
    "    print(f\"Fixed fy: {fy_fixed}\")\n",
    "    print(f\"Varying fx: {list(fx_values)}\")\n",
    "    \n",
    "    for fx in fx_values:\n",
    "        # Generate image\n",
    "        image = create_projection_1280x720(fx, fy_fixed, flip_x=True, flip_y=False)\n",
    "        \n",
    "        # Save image with descriptive filename\n",
    "        filename = f\"calibration_fx{fx}_fy{fy_fixed}_1280x720.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Convert and save\n",
    "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(filepath, image_bgr)\n",
    "        \n",
    "        print(f\"Saved: {filename}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All {len(fx_values)} calibration images saved in '{output_dir}/' folder\")\n",
    "    print(\"üìÅ Browse the images to see how fx affects the horizontal perspective!\")\n",
    "    \n",
    "    return output_dir, list(fx_values)\n",
    "\n",
    "# Generate the fy/fx calibration images\n",
    "output_directory, generated_fx_values = generate_fy_fx_calibration_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92a761",
   "metadata": {},
   "source": [
    "# RealSense Camera Image Reconstruction\n",
    "\n",
    "This notebook helps you reconstruct the original camera view from your 3D point cloud data to match **d435_Color.png**.\n",
    "\n",
    "**Goal**: Find the optimal focal length parameters to recreate the original 1280√ó720 (16:9) camera image.\n",
    "\n",
    "**Process**:\n",
    "1. Load your point cloud data\n",
    "2. Test different focal length values\n",
    "3. Reconstruct the image with original camera dimensions\n",
    "4. Find parameters that best match the original view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963f1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Loaded point cloud with 81669 points\n",
      "Z value range: -3.72266 to -0.21582\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load point cloud (using relative path from utilities folder)\n",
    "pcd = o3d.io.read_point_cloud(\"../d435.ply\")  # Path relative to utilities folder\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "if colors.shape[0] == 0:\n",
    "    raise ValueError(\"Point cloud has no colors!\")\n",
    "\n",
    "print(f\"Loaded point cloud with {len(points)} points\")\n",
    "print(f\"Z value range: {points[:, 2].min()} to {points[:, 2].max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62bf82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 81669 points after filtering for negative Z\n",
      "Z range after filtering: -3.72266 to -0.21582\n",
      "Target reconstruction: 1280x720 (16:9 aspect ratio)\n"
     ]
    }
   ],
   "source": [
    "# Camera setup to match original d435_Color.png (1280x720, 16:9 aspect ratio)\n",
    "img_width, img_height = 1280, 720  # Original camera dimensions\n",
    "cx, cy = img_width // 2, img_height // 2\n",
    "\n",
    "# Filter points in front of camera (adjust based on your coordinate system)\n",
    "valid = points[:, 2] < 0  # Negative Z for RealSense camera\n",
    "x, y, z = points[valid, 0], points[valid, 1], points[valid, 2]\n",
    "colors_filtered = colors[valid]\n",
    "\n",
    "print(f\"Using {len(x)} points after filtering for negative Z\")\n",
    "print(f\"Z range after filtering: {z.min()} to {z.max()}\")\n",
    "print(f\"Target reconstruction: {img_width}x{img_height} (16:9 aspect ratio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7b57b",
   "metadata": {},
   "source": [
    "## How to Use the Tuned Focal Length\n",
    "\n",
    "1. Find the values of `fx` and `fy` that produce the clearest projection of your asparagus stalks\n",
    "2. Update your `main_maskfilter.py` with these values\n",
    "3. If needed, adjust the X and Y flipping options as well\n",
    "4. Re-run your point cloud projection to get more accurate results\n",
    "\n",
    "### Note on RealSense Camera Calibration\n",
    "\n",
    "For even better results, you can use the RealSense SDK to get the exact intrinsic parameters of your camera:\n",
    "\n",
    "```python\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "profile = pipeline.start(config)\n",
    "intrinsics = profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "fx, fy = intrinsics.fx, intrinsics.fy\n",
    "cx, cy = intrinsics.ppx, intrinsics.ppy\n",
    "```\n",
    "\n",
    "This will provide camera-specific calibration parameters rather than approximated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1768c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Image Analysis: d435_Color.png ===\n",
      "Dimensions: 1280 x 720 pixels\n",
      "Aspect Ratio: 1.7778 (1280:720)\n",
      "Color Mode: RGB\n",
      "Format: PNG\n",
      "File Size: 1420517 bytes\n",
      "No EXIF metadata found\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Summary ===\n",
      "d435_Color.png: 1280x720 (AR: 1.778)\n"
     ]
    }
   ],
   "source": [
    "# Image Analysis: Find aspect ratio and metadata\n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import json\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    \"\"\"\n",
    "    Analyze image metadata, aspect ratio, and dimensions\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Open and analyze the image\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            aspect_ratio = width / height\n",
    "            mode = img.mode\n",
    "            format_type = img.format\n",
    "            \n",
    "            print(f\"=== Image Analysis: {os.path.basename(image_path)} ===\")\n",
    "            print(f\"Dimensions: {width} x {height} pixels\")\n",
    "            print(f\"Aspect Ratio: {aspect_ratio:.4f} ({width}:{height})\")\n",
    "            print(f\"Color Mode: {mode}\")\n",
    "            print(f\"Format: {format_type}\")\n",
    "            print(f\"File Size: {os.path.getsize(image_path)} bytes\")\n",
    "            \n",
    "            # Extract EXIF data if available\n",
    "            exifdata = img.getexif()\n",
    "            if exifdata:\n",
    "                print(\"\\n=== EXIF Metadata ===\")\n",
    "                for tag_id in exifdata:\n",
    "                    tag = TAGS.get(tag_id, tag_id)\n",
    "                    data = exifdata.get(tag_id)\n",
    "                    if isinstance(data, bytes):\n",
    "                        data = data.decode('utf-8', errors='ignore')\n",
    "                    print(f\"{tag}: {data}\")\n",
    "            else:\n",
    "                print(\"No EXIF metadata found\")\n",
    "            \n",
    "            return {\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'aspect_ratio': aspect_ratio,\n",
    "                'mode': mode,\n",
    "                'format': format_type,\n",
    "                'file_size': os.path.getsize(image_path)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Analyze key images in the project\n",
    "image_paths = [\n",
    "    \"../d435_Color.png\"  # Original camera image\n",
    "\n",
    "]\n",
    "\n",
    "image_metadata = {}\n",
    "for path in image_paths:\n",
    "    metadata = analyze_image(path)\n",
    "    if metadata:\n",
    "        image_metadata[path] = metadata\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for path, metadata in image_metadata.items():\n",
    "    if metadata:\n",
    "        print(f\"{os.path.basename(path)}: {metadata['width']}x{metadata['height']} (AR: {metadata['aspect_ratio']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae389300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa87240a78244f8b8ef3cbfd24e236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=850.0, description='fx:', max=1500.0, min=400.0, step=10.0), FloatSlid‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive Focal Length Tuning for 1280x720 (16:9) reconstruction\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def create_projection_1280x720(fx, fy, flip_x=True, flip_y=False):\n",
    "    \"\"\"\n",
    "    Project 3D points to 1280x720 image using the given focal lengths\n",
    "    \"\"\"\n",
    "    target_width, target_height = 1280, 720\n",
    "    cx_new, cy_new = target_width // 2, target_height // 2\n",
    "    \n",
    "    # Perspective projection\n",
    "    if flip_x:\n",
    "        u = target_width - ((fx * x / z) + cx_new)\n",
    "    else:\n",
    "        u = (fx * x / z) + cx_new\n",
    "        \n",
    "    if flip_y:\n",
    "        v = target_height - ((fy * y / z) + cy_new)\n",
    "    else:\n",
    "        v = (fy * y / z) + cy_new\n",
    "        \n",
    "    # Clip to image bounds\n",
    "    u_img = np.clip(u, 0, target_width - 1).astype(int)\n",
    "    v_img = np.clip(v, 0, target_height - 1).astype(int)\n",
    "    \n",
    "    # Create image\n",
    "    image = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    depth_buffer = np.full((target_height, target_width), -np.inf)\n",
    "    \n",
    "    # Project points\n",
    "    for i in range(len(u_img)):\n",
    "        ui, vi = u_img[i], v_img[i]\n",
    "        zi = z[i]\n",
    "        \n",
    "        if zi > depth_buffer[vi, ui]:\n",
    "            depth_buffer[vi, ui] = zi\n",
    "            image[vi, ui] = (colors_filtered[i] * 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Interactive widget for focal length tuning\n",
    "@interact(\n",
    "    fx=FloatSlider(min=400, max=1500, step=10, value=850, description='fx:'),\n",
    "    fy=FloatSlider(min=400, max=1500, step=10, value=850, description='fy:'),\n",
    "    flip_x=widgets.Checkbox(value=True, description='Flip X'),\n",
    "    flip_y=widgets.Checkbox(value=False, description='Flip Y')\n",
    ")\n",
    "def tune_focal_length(fx, fy, flip_x, flip_y):\n",
    "    \"\"\"Interactive focal length tuning for 1280x720 reconstruction\"\"\"\n",
    "    image = create_projection_1280x720(fx, fy, flip_x, flip_y)\n",
    "    \n",
    "    plt.figure(figsize=(16, 9))  # 16:9 aspect ratio for display\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"1280x720 Reconstruction - fx={fx}, fy={fy}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Current settings: fx={fx}, fy={fy}, flip_x={flip_x}, flip_y={flip_y}\")\n",
    "    return fx, fy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLOUDPROCESSOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
